<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>MySQL: Metadata Cache</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="mysql.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="logo-mysql-110x55.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">MySQL
   &#160;<span id="projectnumber">8.0.22</span>
   </div>
   <div id="projectbrief">Source Code Documentation</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('group__MDC.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Metadata Cache</div>  </div>
</div><!--header-->
<div class="contents">

<p><h1>Synopsis </h1>
 
<a href="#details">More...</a></p>
<h1>Synopsis </h1>
<p>Metadata Cache plugin communicates with Metadata and Group Replication exposed by the cluster to obtain its topology and availablity information. The digest of this information is then exposed to Routing Plugin in form of a routing table. Key components:</p><ul>
<li>Metadata Cache API - interface through which it exposes its service</li>
<li>Refresh Mechansim - responsible for updating routing table</li>
</ul>
<h1>Glossary </h1>
<p>replicaset = group of servers that contain the same data; in simple cases replicaset and cluster are interchangeable, but in case of sharded cluster this no longer applies, as the cluster will be composed of multiple replicasets, each handling a different shard.</p>
<p>MD = metadata, several tables residing on the metadata server, which (among other things) contain cluster topology information. It reflects the desired "as it should be" version of topology.</p>
<p>GR = Group Replication, a server-side plugin responsible for synchronising data between cluster nodes. It exposes certain dynamic tables (views) that we query to obtain health status of the cluster. It reflects the real "as it actually is" version of topology.</p>
<p>MDC = MD Cache, this plugin (the code that you're reading now).</p>
<p>MM = multi-primary, a replication mode in which all GR members are RW.</p>
<p>SM = single-primary, a replication mode in which only one GR member is RW, rest are RO.</p>
<p>ATTOW = contraction for "at the time of writing".</p>
<p>[xx] (where x is a digit) = reference to a note in Notes section.</p>
<h1>Refresh Mechanism </h1>
<dl class="section note"><dt>Note</dt><dd>To keep docs simpler, all below describes how MDC behaves in case of handling just one replicaset. It has been designed to handle more than one, however, ATTOW we don't test it with more than one, so we are uncertain if it would actually deliver on that promise. This is also the reason why throughout the MDC code there are data structures that are collections of replicasets and for loops that iterate over them, yet in reality we always deal with just one element in those containers and such loops iterate only once.</dd></dl>
<h2>Overview</h2>
<p>MDC refresh runs in its own thread and periodically queries both MD and GR for status, then updates routing table which is queried by the Routing Plugin. Its entry point is <code>MetadataCache::start()</code>, which (indirectly) runs a "forever loop" in <code>MetadataCache::refresh_thread()</code>, which in turn is responsible for perodically running <code>MetadataCache::refresh()</code>.</p>
<p><code>MetadataCache::refresh()</code> is the "workhorse" of refresh mechanism.</p>
<h2>Refresh trigger</h2>
<p><code>MetadataCache::refresh_thread()</code> call to <code>MetadataCache::refresh()</code> can be triggered in 2 ways:</p><ul>
<li><code>&lt;TTL&gt;</code> seconds passed since last refresh</li>
<li>emergency mode (replicaset is flagged to have at least one node unreachable).</li>
</ul>
<p>It's implemented by running a sleep loop between refreshes. The loop sleeps 1 second at a time, until <code>&lt;TTL&gt;</code> iterations have gone or emergency mode is enabled.</p>
<h3>Emergency mode</h3>
<p>Emergency mode is entered, when Routing Plugin discovers that it's unable to connect to a node that's declared by MDC as routable (node that is labelled as writable or readonly). In such situation, it will flag the replicaset as missing a node, and MDC will react by increasing refresh rate to 1/s (if it is currently lower).</p>
<p>This emergency mode will stay enabled, until routing table resulting from most recent MD and GR query is different from the one before it <em>AND</em> the replicaset is in RW mode.</p>
<dl class="section note"><dt>Note</dt><dd>The reason why we require the routing table to be different before we disable the emergency mode, is because it usually takes several seconds for GR to figure out that some node went down. Thus we want to wait until GR gives us a topology that reflects the change. This strategy might have a bug however [05].</dd>
<dd>
The reason why we require the replicaset to be in RW mode before we disable the emergency mode, is the assumption that the user wants the replicaset to be RW and if it is in RO, it is undergoing a failure. This assumption is probably flawed [06].</dd></dl>
<h2>Refresh process</h2>
<p>Once refresh is called, it goes through the following stages:</p><ul>
<li>Stage 1: Query MD</li>
<li>Stage 2: Query GR, combine results with MD, determine availability</li>
<li>Stage 3: Update routing table</li>
</ul>
<p>In subsequent sections each stage is described in more detail</p>
<h3>Stage 1: Query MD</h3>
<p>This stage can be divided into two major substages:</p><ol type="1">
<li>Connect to MD server</li>
<li>Extract MD information</li>
</ol>
<h4>Stage 1.1: Connect to MD server</h4>
<p>Implemented in: <code>ClusterMetadata::connect()</code></p>
<p>MDC starts with a list of MD servers written in the dynamic configuration (state) file, such as:</p>
<p>"cluster-metadata-servers": [ "mysql://192.168.56.101:3310", "mysql://192.168.56.101:3320", "mysql://192.168.56.101:3330" ]</p>
<p>It iterates through the list and tries to connect to each one, until connection succeeds.</p>
<dl class="section note"><dt>Note</dt><dd>This behavior might change in near future, because it does not ensure that connected MD server holds valid MD data [01].</dd>
<dd>
Iteration always starting from 1st server on the list might also change [02].</dd>
<dd>
New connection is always established and old one closed off, even if old one is still alive and usable.</dd></dl>
<h4>Stage 1.2: Extract MD Information</h4>
<p>Implemented in: <code>ClusterMetadata::fetch_instances_from_metadata_server()</code></p>
<p>Using connection established in Stage 1.1, MDC runs a SQL query which extracts a list of nodes (GR members) belonging to the replicaset. Note that this the configured "should be" view of replicaset topology, which might not correspond to actual topology, if for example some nodes became unavailable, changed their role or new nodes were added without updating MD in the server.</p>
<dl class="section note"><dt>Note</dt><dd>ATTOW, if this query fails, whole refresh process fails [03].</dd></dl>
<h3>Stage 2: Query GR, combine results with MD, determine availability</h3>
<p>Implemented in: <code>ClusterMetadata::update_replicaset_status()</code></p>
<p>Here MDC iterates through the list of GR members obtained from MD in Stage 1.2, until it finds a "trustworthy" GR node. A "trustworthy" GR node is one that passes the following substages:</p><ol type="1">
<li>successfully connects</li>
<li>successfully responds to 2 GR status SQL queries</li>
<li>is part of quorum (regardless of whether it's available or not)</li>
</ol>
<p>If MDC doesn't find a "trustworthy" node, it clears the routing table, resulting in Routing Plugin not routing any new connections.</p>
<dl class="section note"><dt>Note</dt><dd>Since Stage 2 got its list of candidate GR nodes from MD server, it follows that MDC will never query any nodes not present in MD for GR status.</dd>
<dd>
Any routing table updates will not go into effect until Stage 3, where it is applied.</dd>
<dd>
ATTOW clearing routing table will not automatically close off old connections. This is a bug which is addressed by upcoming WL#11954.</dd></dl>
<h4>Stage 2.1: Connect to GR node</h4>
<p>Implemented in: <code>ClusterMetadata::update_replicaset_status()</code></p>
<p>New connection to GR node is established (on failure, Stage 2 progresses to next iteration).</p>
<dl class="section note"><dt>Note</dt><dd>Since connection to MD server in Stage 1.1 is not closed after that stage finishes, there's an optimisation done for when connecting to a GR member that's the same node as the MD server - in such case, the connection is simply re-used rather than new one opened.</dd></dl>
<h4>Stage 2.2: Extract GR status</h4>
<p>Implemented in: <code>fetch_group_replication_members()</code> and <code>find_group_replication_primary_member()</code></p>
<p>Two SQL queries are ran and combined to produce a status report of all nodes seen by this node (which would be the entire replicaset if it was in perfect health, or its subset if some nodes became unavailable or the replicaset was experiencing a split-brain scenario):</p>
<ol type="1">
<li>determine the PRIMARY member of the replicaset (if there is more than one, such as in MM setups, the first one is returned and the rest are ignored)</li>
<li>get the membership and health status of all GR nodes, as seen by this node</li>
</ol>
<p>If either SQL query fails to execute, Stage 2 iterates to next GR node.</p>
<dl class="section note"><dt>Note</dt><dd>ATTOW, 1st query is always ran, regardless of whether we're in MM mode or not. As all nodes are PRIMARY in MM setups, we could optimise this query away in MM setups.</dd></dl>
<h4>Stage 2.3: Quorum test</h4>
<p>Implemented in: <code>ClusterMetadata::update_replicaset_status()</code> and <code>ClusterMetadata::check_replicaset_status()</code></p>
<p>MD and GR data collected up to now are compared, to see if GR node just queried belongs to an available replicaset (or to an available replicaset partition, if replicaset has partitioned). For a replicaset (partition) to be considered available, it has to have quorum, that is, meet the following condition: </p><pre class="fragment">count(ONLINE nodes) + count(RECOVERING nodes)
    is greater than
1/2 * count(all original nodes according to MD).
</pre><p>If particular GR node does not meet the quorum condition, Stage 2 iterates to next GR node.</p>
<p>OTOH, if GR node is part of quorum, Stage 2 will not iterate further, because it would be pointless (it's not possible to find a member that's part of another quorum, because there can only be one quorum, the one we just found). This matters, because having quorum does not automatically imply being available, as next paragraph explains.</p>
<p>The availability test will resolve node's replicaset to be in of the 4 possible states:</p><ul>
<li>Unavailable (this node is not part of quorum)</li>
<li>UnavailableRecovering (quorum is met, but it consists of only RECOVERING nodes - this is a rare cornercase)</li>
<li>AvailableWritable (quorum is met, at least one RW node present)</li>
<li>AvailableReadOnly (quorum is met, no RW nodes present)</li>
</ul>
<p>As already mentioned, reaching 1st of the 4 above states will result in Stage 2 iterating to the next node. OTOH, achieving one of remaining 3 states will cause MDC to move on to Stage 3, where it sets the routing table accordingly.</p>
<h5>GR-MD dishorenecy</h5>
<p>ATTOW, our Router has a certain limitation: it assumes that MD contains an exact set or superset of nodes in GR. The user is normally expected to use MySQL Shell to reconfigure the replicaset, which automatically updates both GR and MD, keeping them in sync. But if for some reason the user tinkers with GR directly and adds nodes without updating MD accordingly, availablity/quorum calculations will be skewed. We run checks to detect such situation, and log a warning like so: </p><pre class="fragment">log_error("Member %s:%d (%s) found in replicaset, yet is not defined in
metadata!"
</pre><p>but beyond that we just act defensively by having our quorum calculation be conservative, and error on the side of caution when such discrepancy happens (quorum becomes harder to reach than if MD contained all GR members).</p>
<p>Quorum is evaluated in code as follows: </p><pre class="fragment">bool have_quorum = (quorum_count &gt; member_status.size()/2);
</pre><ul>
<li><code>quorum_count</code> is the sum of PRIMARY, SECONDARY and RECOVERING nodes that appear in MD <em>and</em> GR</li>
<li><code>member_status.size()</code> is the sum of all nodes in GR, regardless of if they show up in MD or not</li>
<li>any nodes in MD but not in GR will be marked as Unavailable, this is an expected scenario, and we react correctly; they do not increment <code>quorum_count</code> nor <code>member_status.size()</code></li>
<li>any nodes in GR but not in MD will never become routing destinations, but they will increment the <code>member_status.size()</code>, making quorum harder to reach.</li>
</ul>
<p>To illustrate how our quorum calculation will behave when GR and MD get out sync, below are some example scenarios:</p>
<h6>Scenario 1</h6>
<pre class="fragment">MD defines nodes A, B, C
GR defines nodes A, B, C, D, E
A, B are alive; C, D, E are dead
</pre><p>Availability calculation should deem replicaset to be unavailable, because only 2 of 5 nodes are alive, even though looking purely from MD point-of-view, 2 of its 3 nodes are still alive, thus could be considered a quorum. In such case: </p><pre class="fragment">quorum_count = 2 (A and B)
member_status.size() = 5
</pre><p>and thus: </p><pre class="fragment">have_quorum = (2 &gt; 5/2) = false
</pre><h6>Scenario 2</h6>
<pre class="fragment">MD defines nodes A, B, C
GR defines nodes A, B, C, D, E
A, B are dead, C, D, E are alive
</pre><p>Availability calculation, if fully GR-aware, could deem replicaset as available, because looking from purely GR perspective, 3 of 5 nodes form quorum. OTOH, looking from MD perspective, only 1 of 3 its nodes (C) is alive.</p>
<p>Our availability calculation prefers to err on the side of caution. So here the availability is judged as not available, even though it could be. But that's the price we pay in exchange for the safety the algorithm provides demonstrated in the previous scenario: </p><pre class="fragment">quorum_count = 1 (C)
member_status.size() = 5
</pre><p>and thus: </p><pre class="fragment">have_quorum = (1 &gt; 5/2) = false
</pre><h6>Scenario 3</h6>
<pre class="fragment">MD defines nodes A, B, C
GR defines nodes       C, D, E
A, B are not reported by GR, C, D, E are alive
</pre><p>According to GR, there's a quorum between nodes C, D and E. However, from MD point-of-view, A and B went missing and only C is known to be alive.</p>
<p>Again, our available calculation prefers to err on the safe side: </p><pre class="fragment">quorum_count = 1 (C)
member_status.size() = 5
</pre><p>and thus: </p><pre class="fragment">have_quorum = (1 &gt; 5/2) = false
</pre><h5>Why don't we just use GR data (and do away with Metadata)?</h5>
<p>Need for cluster configuration aside, there is another challenge. GR can provide IP/hostnames of nodes as it sees them from its own perspective, but those IP/hostnames might not be externally-reachable. OTOH, MD tables provide external IP/hostnames which Router relies upon to reach the GR nodes.</p>
<h3>Stage 3: Update routing table</h3>
<p>Implemented in: <code>MetadataCache::refresh()</code></p>
<p>Once stage 2 is complete, the resulting routing table from Stage 2 is applied. It is also compared to the old routing table and if there is a difference between them, two things happen:</p>
<ol type="1">
<li>Appropriate log messages are issued advising of availability change.</li>
<li>A check is run if replicaset is in RW mode. If it is, emergency mode is called off (see "Emergency mode" section for more information).</li>
</ol>
<h2>NOTES</h2>
<h3>Emergency mode</h3>
<p>[05] Imagine a scenario where a replicaset is perfectly healthy, but Routing Plugin has a network hickup and fails to connect to one of its nodes. As a result, it will flag the replicaset as missing a node, triggerring emergency mode. Emergency mode will only be turned off after routing table changes (the assumption is that the current one is stale and we're waiting for an updated one reflecting the problem Routing Plugin observed). However, since the replicaset is healthy, as long as it stays that way no such update will come, leaving emergency mode enabled indefinitely. This has been reported as BUG#27065614</p>
<p>[06] Requiring replicaset to be available in RW mode before disabling emergency mode has a flaw: if replicaset is placed in super-read-only mode, it is possible for PRIMARY node to be read-only.</p>
<h3>Stage 1.1</h3>
<p>[01] There has been a recent concern ATTOW, that MD returned might be stale, if MD server node is in RECOVERING state. This assumes the MD server is also deployed on an InnoDB cluster.</p>
<p>[02] It might be better to always start from the last successfully-connected server, rather than 1st on the list, to avoid unneccessary connection attempts when 1st server is dead.</p>
<h3>Stage 1.2</h3>
<p>[03] If MD-fetching SQL statement fails to execute or process properly, it will raise an exception that is caught by the topmost catch of the refresh process, meaning, another MD server will not be queried. This is a bug, reported as BUG#28082473 </p>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
